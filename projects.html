---
layout: page
title: Projects
---
<section>
    <div class="row">
        <div class="4u">
            <h5>DeepSpeech</h5>
            <div class="box alt">
                <div class="row uniform 50%">
                    <div class="8u"><a href="https://github.com/mozilla/DeepSpeech/blob/master/DeepSpeech.ipynb"><span class="image fit"><img src="images/deepspeech.png" alt="" /></span></a></div>
                </div>
            </div>
            <p>
            In the last ten years Deep Learning has revolutionized numerous fields: natural language processing, image classification, automatic translation... The list grows longer each day. Speech recognition has also been placed under its spell. DeepSpeech is set to be part of this revolution in speech recognition.
            </p>
            <p>
                DeepSpeech is an open source speech recognition engine we are working on. It is based off of Baidu’s research<a href="https://arxiv.org/abs/1412.5567">[1]</a> and uses the TensorFlow<a href="http://download.tensorflow.org/paper/whitepaper2015.pdf">[2]</a> machine learning framework. It’s currently in early development. If you are interested in contributing, fork our code! 
            </p>
        </div>
        <div class="4u">
            <h5>Murmur</h5>
            <div class="box alt">
                <div class="row uniform 50%">
                    <div class="9u"><a href="https://github.com/mozilla/murmur"><span class="image fit"><img src="images/murmur.jpeg" alt="" /></span></a></div>
                </div>
            </div>
            <p>
            The major problem in open source speech recognition is not with algorithms but is with data. There is simply not enough open source data available! So, we have decided to change that. Introducing Murmur.
            </p>
            <p>
            Murmur is a simple webapp for collecting speech samples to train speech recognition engines. With Murmur we will slowly build a speech corpus to train our open source models. If you are interested in contributing, fork our code!
            </p>
        </div>
        <div class="4u">
            <h5>Pipsqueak</h5>
            <div class="box alt">
                <div class="row uniform 50%">
                    <div class="12u"><a href="https://github.com/mozilla/pipsqueak"><span class="image fit"><img src="images/pipsqueak.png" alt="" /></span></a></div>
                </div>
            </div>
            <p>
            While the majority of Deep Learning speech recognition work has focused on technologies, which are rather wasteful of memory and CPU cycles, a new counter balance is developing that focuses on small footprint devices. Pipsqueak is part of this new trend in Deep Learning speech recognition.
            </p>

            <p>
            The goal of Pipsqueak is to implement the end-to-end deep learning speech recognition engine of McGraw et al.<a href="http://arxiv.org/abs/1603.03185">[2]</a> and to integrate this engine in to Vaani. This will allow Vaani to work completely off-line while still allowing for the high quality speech recognition we have now become used to. If you are interested in contributing, let us know!
            </p>
        </div>
    </div>
</section>
